<<f9a6b164-6ccd-425e-8d78-59eb00dde803>>
* Large language model fine tuning
  :PROPERTIES:
  :CUSTOM_ID: large-language-model-fine-tuning
  :END:
In this notebook we will fine-tune an openai chatGPT model to become a
bio-image analysis expert which responds with recent Python code for
processing images.

See also:

- [[https://lazyprogrammer.me/how-to-fine-tune-chatgpt-gpt-3-5-turbo-using-the-openai-api-in-python/][lazyprogrammer
  tutorial]]
- [[https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates][openai
  blog]]
- [[https://platform.openai.com/docs/guides/fine-tuning/create-a-fine-tuned-model][openai
  tutorial]]
- [[https://platform.openai.com/docs/api-reference/fine-tuning/create][openai
  documentation]]
- [[https://www.datacamp.com/tutorial/fine-tuning-gpt-3-using-the-open-ai-api-and-python][datacamp
  tutorial]]

Todo: We could submit training and validation data separately. This
notebook does not cover this yet due to limited training data. As soon
as we have a larger pool of training data, we can give this a try.

<<a01ed3ec-c34c-47ef-b1e8-87e8c5b575da>>
#+begin_src python
import json
import openai
import time
#+end_src

<<d1d5a6ed-4bcc-46cf-a179-401ff432fc07>>
We first set up training data, a list of chat examples. Most code
examples used below are taken from the
[[https://haesleinhuepf.github.io/BioImageAnalysisNotebooks/intro.html][BioImageAnalysisNotebooks]].

<<0d3f4a69-f8d1-46e7-8726-722fbfac0e58>>
#+begin_src python
training_data = []
#+end_src

<<f35d162f-322c-444e-af17-a29f99ae6c81>>
#+begin_src python
def add_example(input, output):
    training_data.append(
    {
      "messages": [
          { "role": "system", "content": """
You are a chatbot with strong bio-image analysis expertise.
You are an expert python programmer. 
The code you produce will be executed from a Jupyter notebook.
"""},
          {"role": "user", "content": input},
          {"role": "assistant", "content": output}
      ]       
    })

#+end_src

<<94a2f2d0-0554-4d7a-9b26-7d7d5dc98820>>
#+begin_src python
add_example(input="""
How can one open CZI or LIF files using Python?
""", output="""
To open CZI or LIF files, you can use the AICSImageIO package. 
In the following code the file `filename` will be loaded and 
the image data will be stored in `image`.

```python
from aicsimageio import AICSImage
aics_image = AICSImage("../../data/EM_C_6_c0.ome.tif")
aics_image
```

np_image = aics_image.get_image_data("ZYX")
""")
#+end_src

<<5174748b-6973-4ed7-86d0-84c22f0b7f75>>
#+begin_src python
add_example(input="""
How can one show an image, its histogram and some basic statistics in a Jupyter notebook?
""", output="""
You can show an image stored in the variable `image`, its histogram and some basic statistics using the `stackview` library:

```python
import stackview

stackview.insight(image)
```
""")
#+end_src

<<593c0574-8638-45e7-aac1-9515296b8e59>>
#+begin_src python
add_example(input="""
How can one show a label image with every label in a different colour in a Jupyter notebook?
""", output="""
You can show an image stored in the variable `image`, its histogram and some basic statistics using the `stackview` library:

```python
import stackview

stackview.insight(image)
```
""")
#+end_src

<<ab81c631-797c-4dec-a954-c3b2445fd964>>
#+begin_src python
add_example(input="""
How can I show an image in Napari?
""", output="""
Napari is a Python based image viewer and you can use it for showing images and label images like demonstrateed in the following:
```python
import napari

# create a viewer
viewer = napari.Viewer()

# show an image in the viewer
viewer.add_image(image)

# show a label image in the viewer
viewer.add_labels(label_image)
```
""")
#+end_src

<<4d5ea1b9-01f2-46af-8c00-7dddec16885f>>
#+begin_src python
add_example(input="""
How can I remove the background in an image?
""", output="""
You can remove the background in an image using scikit-image's `white_tophat` function. 
In the following example the `input_image` will be background-subtracted and 
the result is stored in `output_image`. 
The variable `radius` allows to specify how large objects should stay while removing the background.

```python
from skimage.morphology import disk
from skimage.morphology import white_tophat

radius = 25

output_image = white_tophat(input_image, disk(radius))
```
""")
#+end_src

<<d2f53cdf-bcfe-431b-8c91-c483fae4bb8d>>
#+begin_src python
add_example(input="""
How can I remove noise in an image?
""", output="""
You can denoise an image using the median filter, e.g. using scikit-image:
In the following example the noise from `input_image` will be removed and 
the result is stored in `output_image`

```python
output_image = filters.median(input_image, disk(1))
```
""")
#+end_src

<<9d8b0412-c5a1-447d-a498-ff1a95aab06c>>
#+begin_src python
add_example(input="""
How can I segment small roundish objects, such as nuclei or granules, in an image?
""", output="""
You can segment and label small roundish objects in an image using the Voronoi-Otsu-Labeling algorithm.
In the following example the objects in `input_image` will be segmented and 
the resulting objects will be labeled and stored in the `label_image`.
The algorithm has two parameters:
* `spot_sigma` allows you to configure how large the objects are supposed to be.
* `outline_sigme` allows you to tune how fine the outlines should be.

In this code, the python library `napari-segment-blobs-and-things-with-membranes` will be used:
```python
import napari_segment_blobs_and_things_with_membranes as nsbatwm

label_image = nsbatwm.voronoi_otsu_labeling(input_image, spot_sigma=2, outline_sigma=2)
```

In case you are using the python library `pyclesperanto-prototype`, you can also call the algorithm like this:

```python
import pyclesperanto_prototype as cle

label_image = cle.voronoi_otsu_labeling(input_image, spot_sigma=2, outline_sigma=2)
```
""")
#+end_src

<<8adcb927-f3a3-4011-906b-4acb07f25f95>>
#+begin_src python
add_example(input="""
How can I segment small roundish objects, such as nuclei, in an image in case they are very densely packed?
""", output="""
You can segment densely packed nuclei in an image using the StarDist library.
In the following example the nuclei in the `input_image` will be segmented and
stored in the `label_image`:

```python
from stardist.models import StarDist2D
from csbdeep.utils import normalize

# creates a pretrained model
model = StarDist2D.from_pretrained('2D_versatile_fluo')

# normalize the image
axis_norm = (0,1)
image = normalize(image, 1,99.8, axis=axis_norm)

# segment the image
label_image, details = model.predict_instances(input_image)
```
""")
#+end_src

<<54f6345c-7159-4f83-a816-9989b09ea38f>>
#+begin_src python
add_example(input="""
How can I segment cells in an image?
""", output="""
You can use the CellPose library for that.
In the following example the cells in the `input_image` will be segmented and
stored in the `label_image`:

```python
from cellpose import models, io

model = models.Cellpose(gpu=False, model_type='cyto')

channels = [0,0] # This means we are processing single-channel greyscale images.

label_image, flows, styles, diams = model.eval(input_image, diameter=None, channels=channels)
```
""")
#+end_src

<<df4e4c9a-ba53-435b-abab-293a57c6042b>>
#+begin_src python
add_example(input="""
How can re-label labels sequentially in a label image?
""", output="""
You can re-label labels in a label image using scikit-image's `relabel_sequential` function like this:

```python
from skimage.segmentation import relabel_sequential

relabeled_image, _, _ = relabel_sequential(label_image)
```
""")
#+end_src

<<40306d47-e439-4875-b550-d92fc0c2ed92>>
#+begin_src python
add_example(input="""
How can expand labels e.g. with a radius of 10 pixels in a label image?
""", output="""
You can expand labels in a label image using scikit-image's `expand_labels` function like this:

```python
from skimage.segmentation import expand_labels

expanded_labels = expand_labels(filtered_label_image, distance=10)
```
""")
#+end_src

<<0d3bdf39-3d19-4ceb-8c00-be0cc3f5cc5e>>
** Preparing training data
   :PROPERTIES:
   :CUSTOM_ID: preparing-training-data
   :END:
We need to reformat the data in the [[https://jsonlines.org/][JSON-lines
format]].

<<9c5e0ce7-03ff-43ff-8195-7a4654e85ce2>>
#+begin_src python
def prepare_data(dictionary_data, final_file_name):
    
    with open(final_file_name, 'w') as outfile:
        for entry in dictionary_data:
            json.dump(entry, outfile)
            outfile.write('\n')

prepare_data(training_data, "training_data.jsonl")
#+end_src

<<9cc88330-3438-45f4-b573-0899f27313b5>>
** Uploading training data
   :PROPERTIES:
   :CUSTOM_ID: uploading-training-data
   :END:
We can upload the training data like this:

<<e5a326d6-e126-40f6-9780-67bfc3ff8247>>
#+begin_src python
training_file = openai.File.create(
  file=open('training_data.jsonl'),
  purpose='fine-tune',
)
training_file
#+end_src

#+begin_example
<File file id=file-xiweY94J061YDcLr7gJZAiWz at 0x1b3f63d2810> JSON: {
  "object": "file",
  "id": "file-xiweY94J061YDcLr7gJZAiWz",
  "purpose": "fine-tune",
  "filename": "file",
  "bytes": 8156,
  "created_at": 1698937116,
  "status": "processed",
  "status_details": null
}
#+end_example

<<eef6150a-348e-473c-b444-a108c29bea41>>
Afterwards, we need to wait until the file is done processing.

<<a584547e-3023-4cf9-b40a-102cdde7da8c>>
#+begin_src python
while openai.File.retrieve(training_file.id).status != "processed":
    print("Still processing")
    time.sleep(30)
#+end_src

<<6d1eb62b-42df-40e1-898a-173e97083e30>>
** Model training
   :PROPERTIES:
   :CUSTOM_ID: model-training
   :END:
Once the training data is uploaded and processed, we can use it for
training.

<<67d50042-410e-4e2d-8ebb-ec9bbfd8c3ce>>
#+begin_src python
job = openai.FineTuningJob.create(training_file=training_file.id, model="gpt-3.5-turbo")
job
#+end_src

#+begin_example
<FineTuningJob fine_tuning.job id=ftjob-3ZhPTB0pT3yJENRfutRUQju5 at 0x1b3f4b501d0> JSON: {
  "object": "fine_tuning.job",
  "id": "ftjob-3ZhPTB0pT3yJENRfutRUQju5",
  "model": "gpt-3.5-turbo-0613",
  "created_at": 1698937123,
  "finished_at": null,
  "fine_tuned_model": null,
  "organization_id": "org-1cjvymf23JI7jxFOJCdnbsE2",
  "result_files": [],
  "status": "validating_files",
  "validation_file": null,
  "training_file": "file-xiweY94J061YDcLr7gJZAiWz",
  "hyperparameters": {
    "n_epochs": "auto"
  },
  "trained_tokens": null,
  "error": null
}
#+end_example

<<3af8f675-ca77-4e7c-935c-f3664e03d83d>>
Also training will take a while and we need to wait until it succeeded.

<<230223cc-4af9-474b-a461-d55ec1d16a25>>
#+begin_src python
while openai.FineTuningJob.retrieve(job.id).status !=  "succeeded":
    print("Still training")
    time.sleep(30)
#+end_src

#+begin_example
Still training
Still training
Still training
Still training
Still training
Still training
Still training
Still training
Still training
Still training
Still training
Still training
Still training
Still training
Still training
Still training
Still training
Still training
Still training
Still training
#+end_example

<<29663343-a06a-4f59-8126-266891fcdd2b>>
We can then retrieve the model name and execute the model.

<<d1881eab-7deb-48eb-ba83-7f4d805e26c3>>
#+begin_src python
job_status = openai.FineTuningJob.retrieve(job.id)

model_name = job_status.fine_tuned_model
model_name
#+end_src

#+begin_example
'ft:gpt-3.5-turbo-0613:personal::8GTbD6B7'
#+end_example

<<cd7b98e3-0199-4ab5-9948-3ccdd6ca3d56>>
#+begin_src python
completion = openai.ChatCompletion.create(
  model=model_name,
  messages=[
    {"role": "system", "content": "You are a chatbot with strong bio-image analysis expertise."},
    {"role": "user", "content": "How can I segment an image showing dense nuclei in Python?"}
  ]
)
print(completion.choices[0].message["content"])
#+end_src

#+begin_example
You can segment an image showing dense nuclei in Python using the scikit-image library. Here's an example using the Otsu thresholding method:

```python
from skimage.filters import threshold_otsu
from skimage.segmentation import clear_border
from skimage.measure import label
from skimage.segmentation import watershed

# Assume your input image is stored in the `input_image` variable

# Apply Otsu thresholding
threshold = threshold_otsu(input_image)
binary_image = input_image > threshold

# Remove border artifacts
cleared = clear_border(binary_image)

# Label the image
label_image = label(cleared)

# Apply watershed
image_label_overlay = watershed(-input_image, label_image)

# The resulting segmented image is stored in the `image_label_overlay` variable
```

For more advanced segmentation algorithms, you can have a look at the Cellpose or StarDist libraries, which provide more accurate segmentation of cells and nuclei:

- Cellpose: https://cellpose.readthedocs.io
- StarDist: https://github.com/stardist/stardist

Let me know if you need more help!
#+end_example

<<43ec9c4b-8fe0-40ec-81a2-05f4a5d4112a>>
#+begin_src python
#+end_src
