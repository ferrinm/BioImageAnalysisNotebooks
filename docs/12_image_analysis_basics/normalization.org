* Image Normalization
  :PROPERTIES:
  :CUSTOM_ID: image-normalization
  :END:

[[https://en.wikipedia.org/wiki/Normalization_(image_processing)][Normalization]]
is commonly used for *preprocessing* biological images. It is also
commonly used for deep learning-based approaches. During normalization,
the range of pixel intensity values is changed. Therefore, it is crucial
for differing pixel intensities between images to ensure comparability
and quantification of biological features across different images.

However, while normalization can enhance consistency and detectability
of patterns, it can also lead to distortion, i.e. suppression or
exaggeration of signals, if it is not carefully applied. Finding the
balance between noise reduction and risk of losing biological
variability is crucial for successfully analyzing images.

This notebook is meant gives an *overview of different normalization
techniques*. In the end, we will investigate *possible impacts and risks
of normalization* that need to be considered.

** Overview
   :PROPERTIES:
   :CUSTOM_ID: overview
   :END:

| *Normalization Technique*        | *Formula*                                         | *Description*                                                                                | *Advantages*                                                        | *Disadvantages*                                                             |
|----------------------------------+---------------------------------------------------+----------------------------------------------------------------------------------------------+---------------------------------------------------------------------+-----------------------------------------------------------------------------|
| *Min-Max Normalization*          | \[ X' = \frac{X - X_{min}}{X_{max} - X_{min}} \]  | Rescales data to fixed range, typically [0, 1].                                              | Simple implementation, preserves relationships between data points. | Sensitivity to outliers can distort data distribution.                      |
| *Percentile-Based Normalization* | \[ X' = \frac{X - P_{low}}{P_{high} - P_{low}} \] | Takes into account relative rank of each intensity in the distribution (e.g., 1st and 99th). | Reduces influence of outliers.                                      | Requires careful selection of percentiles, may not represent all data well. |
| *Z-Score Normalization*          | \[ Z = \frac{X - \mu}{\sigma} \]                  | Standardizes data by removing mean and scaling to unit variance.                             | Useful for normally distributed data, reduces effect of outliers.   | Assumes normality, may not perform well with non-Gaussian data.             |

** Techniques
   :PROPERTIES:
   :CUSTOM_ID: techniques
   :END:

#+begin_src python
from skimage.io import imread
import numpy as np
import matplotlib.pyplot as plt
from stackview import insight
#+end_src

For demonstrating how normalization works, we will use =blobs.tif= as an
example image.

#+begin_src python
image = imread('../../data/blobs.tif')
#+end_src

Now we can use =stackview.insight= to display the image and essential
properties of the image:

#+begin_src python
insight(image)
#+end_src

#+begin_example
StackViewNDArray([[ 40,  32,  24, ..., 216, 200, 200],
                  [ 56,  40,  24, ..., 232, 216, 216],
                  [ 64,  48,  24, ..., 240, 232, 232],
                  ...,
                  [ 72,  80,  80, ...,  48,  48,  48],
                  [ 80,  80,  80, ...,  48,  48,  48],
                  [ 96,  88,  80, ...,  48,  48,  48]], dtype=uint8)
#+end_example

We can see that our image is of datatype unsigned 8-bit integer, short
=uint8=. This means:

- *unsigned*: the values are always positive
- *8-bit*: we can have 2^8 = 256 different intensity levels ranging from
  0 to 255.
- *integer*: the values are whole numbers

We can also see how these intensity levels are distributed in the
intensity histogram. Lets try out different ways to normalize this
image:

*** Min-Max Normalization
    :PROPERTIES:
    :CUSTOM_ID: min-max-normalization
    :END:

One of the most common ways to normalize data is
[[https://en.wikipedia.org/wiki/Feature_scaling#Methods][min-max
normalization]]. Let us try it out:

#+begin_src python
min_max = (image - image.min()) / (image.max() - image.min())
insight(min_max)
#+end_src

#+begin_example
StackViewNDArray([[0.13333333, 0.1       , 0.06666667, ..., 0.86666667,
                   0.8       , 0.8       ],
                  [0.2       , 0.13333333, 0.06666667, ..., 0.93333333,
                   0.86666667, 0.86666667],
                  [0.23333333, 0.16666667, 0.06666667, ..., 0.96666667,
                   0.93333333, 0.93333333],
                  ...,
                  [0.26666667, 0.3       , 0.3       , ..., 0.16666667,
                   0.16666667, 0.16666667],
                  [0.3       , 0.3       , 0.3       , ..., 0.16666667,
                   0.16666667, 0.16666667],
                  [0.36666667, 0.33333333, 0.3       , ..., 0.16666667,
                   0.16666667, 0.16666667]])
#+end_example

Min-max normalization leads to the transformation of the minimum
intensity value of the image into a 0 and the maximum intensity value
gets transformed into a 1. Then, every value lies between 0 and 1.

Therefore, we need to be able to represent decimal values and not whole
numbers. Consequently, we cannot use a dtype of =uint8= anymore but need
the floating point representation, here =float64=.

Let us compare the intensity histograms of our original and the
min-max-normalized image:

#+begin_src python
# Plot the histograms
fig, axes = plt.subplots(1, 2, figsize=(12, 5))  

# Original image histogram
axes[0].hist(image.ravel(), bins=50, color='darkblue')
axes[0].set_title('Original Image Histogram')
axes[0].set_xlabel('Pixel Intensity')
axes[0].set_ylabel('Frequency')

# Min-max normalized image histogram
axes[1].hist(min_max.ravel(), bins=50, color='darkblue')
axes[1].set_title('Min-Max Normalized Image Histogram')
axes[1].set_xlabel('Pixel Intensity')
axes[1].set_ylabel('Frequency')

plt.tight_layout()  
plt.show()
#+end_src

[[file:701ae97b1fec12582d67e21b9a9451c5988096d7.png]]

We can see that the two histograms look very similar and the min-max
normalization ensures that pixel values are scaled to a common range,
here 0 to 1. This is particularly useful when working with different
datasets that need to be compared or used, for example for a machine
learning algorithm.

*** Percentile-based Normalization
    :PROPERTIES:
    :CUSTOM_ID: percentile-based-normalization
    :END:

Percentile-based normalization takes into account the relative rank of
each intensity in the distribution, making it more robust against
outliers. This approach leads to less skewing of the distribution as the
focus is on where the intensity value lies in the overall distribution.

#+begin_src python
# Compute percentiles
p1 = np.percentile(image, 1)
p99 = np.percentile(image, 99)

# Perform percentile normalization
percentile_image_unclipped = (image - p1) / (p99 - p1)
insight(percentile_image_unclipped)
#+end_src

#+begin_example
StackViewNDArray([[0.07142857, 0.03571429, 0.        , ..., 0.85714286,
                   0.78571429, 0.78571429],
                  [0.14285714, 0.07142857, 0.        , ..., 0.92857143,
                   0.85714286, 0.85714286],
                  [0.17857143, 0.10714286, 0.        , ..., 0.96428571,
                   0.92857143, 0.92857143],
                  ...,
                  [0.21428571, 0.25      , 0.25      , ..., 0.10714286,
                   0.10714286, 0.10714286],
                  [0.25      , 0.25      , 0.25      , ..., 0.10714286,
                   0.10714286, 0.10714286],
                  [0.32142857, 0.28571429, 0.25      , ..., 0.10714286,
                   0.10714286, 0.10714286]])
#+end_example

Now, we can clip the values to the range [0, 1] for better comparability
and visualize the result:

#+begin_src python
percentile_image_clipped = np.clip(percentile_image_unclipped, 0, 1)  
insight(percentile_image_clipped)
#+end_src

#+begin_example
StackViewNDArray([[0.07142857, 0.03571429, 0.        , ..., 0.85714286,
                   0.78571429, 0.78571429],
                  [0.14285714, 0.07142857, 0.        , ..., 0.92857143,
                   0.85714286, 0.85714286],
                  [0.17857143, 0.10714286, 0.        , ..., 0.96428571,
                   0.92857143, 0.92857143],
                  ...,
                  [0.21428571, 0.25      , 0.25      , ..., 0.10714286,
                   0.10714286, 0.10714286],
                  [0.25      , 0.25      , 0.25      , ..., 0.10714286,
                   0.10714286, 0.10714286],
                  [0.32142857, 0.28571429, 0.25      , ..., 0.10714286,
                   0.10714286, 0.10714286]])
#+end_example

#+begin_src python
# Create a 2x3 subplot grid (2 rows, 3 columns)
fig, axes = plt.subplots(2, 3, figsize=(20, 10))  

# Show the original image
axes[0, 0].imshow(image, cmap='gray')
axes[0, 0].set_title('Original Image')
axes[0, 0].axis('off')  # Hide axes

# Show the min-max normalized image
axes[0, 1].imshow(min_max, cmap='gray')
axes[0, 1].set_title('Min Max Normalized Image')
axes[0, 1].axis('off')  # Hide axes

# Show the percentile-based normalized image
axes[0, 2].imshow(percentile_image_clipped, cmap='gray')
axes[0, 2].set_title('Percentile Normalized Image')
axes[0, 2].axis('off')  # Hide axes

# Original image histogram
axes[1, 0].hist(image.ravel(), bins=50, color='darkblue')
axes[1, 0].set_title('Image Histogram')
axes[1, 0].set_xlabel('Pixel Intensity')
axes[1, 0].set_ylabel('Frequency')

# Min-max normalized image histogram
axes[1, 1].hist(min_max.ravel(), bins=50, color='darkblue')
axes[1, 1].set_title('Min Max Normalization Histogram')
axes[1, 1].set_xlabel('Pixel Intensity')
axes[1, 1].set_ylabel('Frequency')

# Percentile-based normalized image histogram
axes[1, 2].hist(percentile_image_clipped.ravel(), bins=50, color='darkblue')
axes[1, 2].set_title('Percentile-based Normalization Histogram')
axes[1, 2].set_xlabel('Pixel Intensity')
axes[1, 2].set_ylabel('Frequency')

# Adjust layout for better spacing
plt.tight_layout()
plt.show()
#+end_src

[[file:d592ec8fcb46de616a90b910ef86e5e64d9f8bb5.png]]

We can see that the original image and the min-max normalized image have
a very similar appearance and intensity histogram. Because of the
clipping, the image which was normalized using percentiles seems to
appear with a slightly higher contrast.

** Exercise
   :PROPERTIES:
   :CUSTOM_ID: exercise
   :END:

Another type of normalization is the
[[https://www.statology.org/z-score-normalization/#:~:text=Z%2Dscore%20normalization%20refers%20to,the%20standard%20deviation%20is%201.][Z-score
normalization]]. It transforms the image such that it has a mean of 0
and standard deviation of 1 based on the following formula:

\[
Z = \frac{(X - \mu)}{\sigma}
\]

How would you implement the z-score normalization in python?

** Impact and risk of normalization
   :PROPERTIES:
   :CUSTOM_ID: impact-and-risk-of-normalization
   :END:

#+begin_src python
nuclei = imread('../../data/BBBC007_batch/17P1_POS0013_D_1UL.tif')
insight(nuclei)
#+end_src

#+begin_example
StackViewNDArray([[3, 3, 3, ..., 2, 3, 3],
                  [5, 4, 4, ..., 3, 3, 2],
                  [6, 5, 4, ..., 2, 3, 2],
                  ...,
                  [2, 1, 1, ..., 1, 1, 1],
                  [1, 2, 2, ..., 2, 1, 1],
                  [2, 2, 1, ..., 1, 1, 1]], dtype=uint16)
#+end_example

Now, imagine that during image acquisition, there was a pixel that
failed to change color as expected. This is a common problem in
microscopy. Hereby, we can decide between "dead pixels" (remain
permanently black) and "stuck pixels" (remain permanently stuck in a
bright state).

#+begin_src python
nuclei_stuck = nuclei.copy()
nuclei_stuck[150:153, 150:153] = 1000  
insight(nuclei_stuck)
#+end_src

#+begin_example
StackViewNDArray([[3, 3, 3, ..., 2, 3, 3],
                  [5, 4, 4, ..., 3, 3, 2],
                  [6, 5, 4, ..., 2, 3, 2],
                  ...,
                  [2, 1, 1, ..., 1, 1, 1],
                  [1, 2, 2, ..., 2, 1, 1],
                  [2, 2, 1, ..., 1, 1, 1]], dtype=uint16)
#+end_example

We can see that our initial distribution is now skewed because the
outlier is so far off the other values.

#+begin_src python
# show nuclei and nuclei_stuck side by side
fig, axes = plt.subplots(1, 2, figsize=(12, 6))

axes[0].imshow(nuclei, cmap='gray')
axes[0].set_title('Original Image')
axes[0].axis('off')

axes[1].imshow(nuclei_stuck, cmap='gray')
axes[1].set_title('Stuck Pixel Image')
axes[1].axis('off')

plt.tight_layout()
plt.show()
#+end_src

[[file:bc9c9fb872bef7e36201326ed8e8ee63de4cfd60.png]]

This results in a lack of contrast in the case with the stuck pixel. Let
us investigate how it impacts the min-max normalization.

#+begin_src python
min_max_stuck = (nuclei_stuck - nuclei_stuck.min()) / (nuclei_stuck.max() - nuclei_stuck.min())
insight(min_max_stuck)
#+end_src

#+begin_example
StackViewNDArray([[0.002002  , 0.002002  , 0.002002  , ..., 0.001001  ,
                   0.002002  , 0.002002  ],
                  [0.004004  , 0.003003  , 0.003003  , ..., 0.002002  ,
                   0.002002  , 0.001001  ],
                  [0.00500501, 0.004004  , 0.003003  , ..., 0.001001  ,
                   0.002002  , 0.001001  ],
                  ...,
                  [0.001001  , 0.        , 0.        , ..., 0.        ,
                   0.        , 0.        ],
                  [0.        , 0.001001  , 0.001001  , ..., 0.001001  ,
                   0.        , 0.        ],
                  [0.001001  , 0.001001  , 0.        , ..., 0.        ,
                   0.        , 0.        ]])
#+end_example

Min-max normalization is highly sensitive to these kind of outliers as
it takes into account the minimum and maximum intensity value to
determine the range of normalization. But how about percentile-based
normalization?

#+begin_src python
p1_stuck = np.percentile(nuclei_stuck, 0.1)
p99_stuck = np.percentile(nuclei_stuck, 99.9)

percentile_stuck_unclipped = (nuclei_stuck - p1_stuck) / (p99_stuck - p1_stuck)
insight(percentile_stuck_unclipped)
#+end_src

#+begin_example
StackViewNDArray([[0.01025641, 0.01025641, 0.01025641, ..., 0.00512821,
                   0.01025641, 0.01025641],
                  [0.02051282, 0.01538462, 0.01538462, ..., 0.01025641,
                   0.01025641, 0.00512821],
                  [0.02564103, 0.02051282, 0.01538462, ..., 0.00512821,
                   0.01025641, 0.00512821],
                  ...,
                  [0.00512821, 0.        , 0.        , ..., 0.        ,
                   0.        , 0.        ],
                  [0.        , 0.00512821, 0.00512821, ..., 0.00512821,
                   0.        , 0.        ],
                  [0.00512821, 0.00512821, 0.        , ..., 0.        ,
                   0.        , 0.        ]])
#+end_example

You can also play around with the percentiles, I chose here =0.1= and
=99.9=. Now, let us clip the image in the range [0,1]:

#+begin_src python
percentile_stuck_clipped = np.clip(percentile_stuck_unclipped, 0, 1)  
insight(percentile_stuck_clipped)
#+end_src

#+begin_example
StackViewNDArray([[0.01025641, 0.01025641, 0.01025641, ..., 0.00512821,
                   0.01025641, 0.01025641],
                  [0.02051282, 0.01538462, 0.01538462, ..., 0.01025641,
                   0.01025641, 0.00512821],
                  [0.02564103, 0.02051282, 0.01538462, ..., 0.00512821,
                   0.01025641, 0.00512821],
                  ...,
                  [0.00512821, 0.        , 0.        , ..., 0.        ,
                   0.        , 0.        ],
                  [0.        , 0.00512821, 0.00512821, ..., 0.00512821,
                   0.        , 0.        ],
                  [0.00512821, 0.00512821, 0.        , ..., 0.        ,
                   0.        , 0.        ]])
#+end_example

#+begin_src python
# Create a 2x3 subplot grid (2 rows, 3 columns)
fig, axes = plt.subplots(2, 4, figsize=(20, 10))  

# Show the original image
axes[0, 0].imshow(nuclei, cmap='gray')
axes[0, 0].set_title('Original Image')
axes[0, 0].axis('off')  # Hide axes

# Show the image with a stuck pixel
axes[0, 1].imshow(nuclei_stuck, cmap='gray')
axes[0, 1].set_title('Stuck Pixel Image')
axes[0, 1].axis('off')  # Hide axes

# Show the min-max normalized image
axes[0, 2].imshow(min_max_stuck, cmap='gray')
axes[0, 2].set_title('Min Max Normalized Image')
axes[0, 2].axis('off')  # Hide axes

# Show the percentile-based normalized image
axes[0, 3].imshow(percentile_stuck_clipped, cmap='gray')
axes[0, 3].set_title('Percentile Normalized Image')
axes[0, 3].axis('off')  # Hide axes

# Original image histogram
axes[1, 0].hist(nuclei.ravel(), bins=50, color='darkblue')
axes[1, 0].set_title('Image Histogram')
axes[1, 0].set_xlabel('Pixel Intensity')
axes[1, 0].set_ylabel('Frequency')

# Stuck pixel image histogram
axes[1, 1].hist(nuclei_stuck.ravel(), bins=50, color='darkblue')
axes[1, 1].set_title('Stuck Pixel Image Histogram')
axes[1, 1].set_xlabel('Pixel Intensity')
axes[1, 1].set_ylabel('Frequency')

# Min-max normalized image histogram
axes[1, 2].hist(min_max_stuck.ravel(), bins=50, color='darkblue')
axes[1, 2].set_title('Min Max Normalization Histogram')
axes[1, 2].set_xlabel('Pixel Intensity')
axes[1, 2].set_ylabel('Frequency')

# Percentile-based normalized image histogram
axes[1, 3].hist(percentile_stuck_clipped.ravel(), bins=50, color='darkblue')
axes[1, 3].set_title('Percentile-based Normalization Histogram')
axes[1, 3].set_xlabel('Pixel Intensity')
axes[1, 3].set_ylabel('Frequency')

# Adjust layout for better spacing
plt.tight_layout()
plt.show()
#+end_src

[[file:43f553deaae007dc43594d2dada415bc650cdaa6.png]]

*** Summary
    :PROPERTIES:
    :CUSTOM_ID: summary
    :END:

What can we learn from this? If an image contains very dark or, like in
our case, bright pixels (e.g. due to noise or artifacts), these extreme
values stretch the normalization range, causing most of the pixel values
to be squeezed into a narrow range. This compression results in a lower
contrast in the rest of the image. A way to circumvent this behavior is
to use Percentile-based Normalization. Percentile-based Normalization
takes into account the relative rank of each intensity in the
distribution, making it more robust against outliers. This approach
leads to less skewing of the distribution as the focus is on where the
intensity value lies in the overall distribution.
