<<06e6b903-c670-4061-9559-eabca80a566d>>
* Divide and rule
  :PROPERTIES:
  :CUSTOM_ID: divide-and-rule
  :END:
Sometimes, programs become very long and hard to read. We speak of
[[https://en.wikipedia.org/wiki/Spaghetti_code][spaghetti code]]. One
way for making code easier to read and to maintain is to divide it into
smaller functions and just use them in more complex workflows. The
software design principle is called
[[https://www.quora.com/What-is-divide-and-conquer-programming-strategy][Divide
and rule]].

<<484f7356-0703-416e-88fc-cb760f325e3f>>
#+begin_src python
from skimage.io import imread
from skimage.morphology import white_tophat, disk
from skimage.filters import gaussian, threshold_otsu
from skimage.measure import label, regionprops_table
import pandas as pd
import numpy as np
#+end_src

<<4ae5ecf1-322d-4555-a0af-45dba03a11bb>>
#+begin_src python
image = imread("../../data/blobs.tif")
footprint = disk(15)
background_subtracted = white_tophat(image, 
                                     footprint=footprint)
particle_radius = 5
denoised = gaussian(background_subtracted, 
                    sigma=particle_radius)
binary = denoised > threshold_otsu(denoised)
labels = label(binary)
requested_measurements = ["label", "area", "mean_intensity"]
regionprops = regionprops_table(image, 
                                labels, 
                                properties=requested_measurements)
table = pd.DataFrame(regionprops)
mean_total_intensity = np.mean(table["area"] * table["mean_intensity"])
mean_total_intensity
#+end_src

#+begin_example
17136.90322580645
#+end_example

<<27e898db-d8b5-4886-9182-3a55ba24e44a>>
A common and easy way for making such code easier to read is to split it
into sections which start with a comment each.

<<342007b6-dc86-41cb-b3de-7a23a1f57f57>>
#+begin_src python
# configuration
file_to_analyze = "../../data/blobs.tif"
background_subtraction_radius = 15
particle_radius = 5
requested_measurements = ["area", "mean_intensity"]

# load data
image = imread(file_to_analyze)

# preprocess image
footprint = disk(background_subtraction_radius)
background_subtracted = white_tophat(image, 
                                     footprint=footprint)
denoised = gaussian(background_subtracted, 
                    sigma=particle_radius)

# segment image
binary = denoised > threshold_otsu(denoised)
labels = label(binary)

# extract features
regionprops = regionprops_table(image, 
                                labels, 
                                properties=requested_measurements)
table = pd.DataFrame(regionprops)

# descriptive statistics
mean_total_intensity = np.mean(table["area"] * table["mean_intensity"])
mean_total_intensity
#+end_src

#+begin_example
17136.90322580645
#+end_example

<<332bb3d0-88c3-465b-a60f-9dd2449dd959>>
More professional would be to put all this code into meaningful
sub-routines and call them from a central function.

<<28e3f126-622b-47ed-b03e-90a6ae6e333c>>
#+begin_src python
# reusable functions
def preprocess_image(image, background_subtraction_radius, particle_radius):
    """Apply background removal and denoising"""
    footprint = disk(background_subtraction_radius)
    background_subtracted = white_tophat(image, footprint=footprint)
    denoised = gaussian(background_subtracted, sigma=particle_radius)
    return denoised

def segment_image(image):
    """Apply thresholding and connected component analysis"""
    binary = image > threshold_otsu(image)
    labels = label(binary)
    return labels

def extract_features(image, labels, requested_measurements):
    """Measure specified properties"""
    regionprops = regionprops_table(image, 
                                    labels, 
                                    properties=requested_measurements)
    table = pd.DataFrame(regionprops)
    return table
#+end_src

<<b4676135-ec60-4d49-accc-5beab2d94449>>
After we put groups of processing steps into functions, we can call them
from a major function. This function can later be reused to apply the
same procedure to all images in a folder. It also serves as index, an
overview about the image processing workflow. By reding just this
function, we know all processing steps and what parameters they have.

<<6f77d663-764b-45de-8668-600d8465561b>>
#+begin_src python
def analyse_average_total_intensity(filename, 
                                    background_subtraction_radius = 15, 
                                    particle_radius = 5):
    """Load an image, segment objects and measure their mean total intensity."""
    image = imread(filename)
    denoised = preprocess_image(image, 
                                background_subtraction_radius, 
                                particle_radius)
    labels = segment_image(denoised)
    requested_measurements = ["area", "mean_intensity"]
    table = extract_features(image, 
                             labels, 
                             requested_measurements)

    # descriptive statistics
    mean_total_intensity = np.mean(table["area"] * table["mean_intensity"])
    
    return mean_total_intensity
#+end_src

<<4ed16cc5-8517-413f-84e8-3498224b5c46>>
#+begin_src python
# configuration
file_to_analyze = "../../data/blobs.tif"
#+end_src

<<1f1fa453-cedd-4c9c-9708-9937b49b72c0>>
This central function can then be read easily; it has just 6 lines of
code

<<a076194f-8917-4cd4-93d8-eb81cb02fea7>>
#+begin_src python
analyse_average_total_intensity(file_to_analyze)
#+end_src

#+begin_example
17136.90322580645
#+end_example

<<b66687a9-71c4-4d82-a4ac-678bb7eb587a>>
This function can then be reused also for other image files.

<<a30f8c95-340c-4321-a40e-176bda977409>>
#+begin_src python
analyse_average_total_intensity("../../data/BBBC007_batch/20P1_POS0005_D_1UL.tif")
#+end_src

#+begin_example
884.2620087336245
#+end_example

<<5a5ff78b-b1ba-48c1-8214-0f7a2c6b6641>>
#+begin_src python
#+end_src
