<<732e751d>>
* Pixel classification in multi-channel images
  :PROPERTIES:
  :CUSTOM_ID: pixel-classification-in-multi-channel-images
  :END:
APOC also accepts lists of images as input for training and prediction.
This can be used for example for semantic segmentation in multi-channel
images showing nuclei, membranes and cytoplasm in between.

<<9143b0ba>>
#+begin_src python
from skimage.data import cells3d
from skimage.io import imsave, imread
import napari
import numpy as np
import matplotlib.pyplot as plt
from pyclesperanto_prototype import imshow
#+end_src

<<54ede16b>>
#+begin_src python
image = cells3d()
#+end_src

<<a81db9ca>>
#+begin_src python
image_ch1 = image[30, 0]
imshow(image_ch1)
#+end_src

[[file:8467a0933b6e7eb032a27bd55b11e38d71fc58dc.png]]

<<975f4130>>
#+begin_src python
image_ch2 = image[30, 1]
imshow(image_ch2)
#+end_src

[[file:fd07cd5dc8db8dbeb93b9ba2daf8a7134fe87532.png]]

<<9fd82430>>
#+begin_src python
filename = '../../data/cells_annotation.tif'
            
annotation = imread(filename)
#+end_src

<<abe6ffdf-f03b-437a-a9d5-3a4bcacff402>>
#+begin_src python
fix, axs = plt.subplots(2,2, figsize=(10,10))

imshow(image_ch1, plot=axs[0,0], colormap="Greens_r")
imshow(image_ch2, plot=axs[0,1], colormap="Purples_r")
imshow(annotation, labels=True, plot=axs[1,0])
imshow(image_ch1, continue_drawing=True, plot=axs[1,1], colormap="Greens_r", alpha=0.5)
imshow(image_ch2, continue_drawing=True, plot=axs[1,1], colormap="Purples_r", alpha=0.5)
imshow(annotation, labels=True, plot=axs[1,1], alpha=0.5)
#+end_src

[[file:df6ff466e2c0f4120a34f9fafea778aff402b21a.png]]

<<5886d836-4f2d-4501-ae67-ec92dd6d519f>>
** Training
   :PROPERTIES:
   :CUSTOM_ID: training
   :END:

<<208609e7>>
#+begin_src python
from apoc import PixelClassifier

# define features
features = "sobel_of_gaussian_blur=2 laplace_box_of_gaussian_blur=2 gaussian_blur=2 sobel_of_gaussian_blur=4 laplace_box_of_gaussian_blur=4 gaussian_blur=4"

# this is where the model will be saved
cl_filename = 'test.cl'

clf = PixelClassifier(opencl_filename=cl_filename)
clf.train(features=features, ground_truth=annotation, image=[image_ch1, image_ch2])
#+end_src

<<52accafc-df3b-42ec-8203-53d10ad13f94>>
** Prediction
   :PROPERTIES:
   :CUSTOM_ID: prediction
   :END:

<<3e15ef7d>>
#+begin_src python
result = clf.predict(image=[image_ch1, image_ch2])
imshow(result, labels=True)
#+end_src

[[file:cb99d932c9d957a3a2357a608de89b19845b38bf.png]]
