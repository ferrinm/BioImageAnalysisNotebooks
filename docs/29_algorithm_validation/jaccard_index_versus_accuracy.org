<<86c146e0-c557-43f5-b372-4899c856f299>>
* Jaccard-Index versus Accuracy
  :PROPERTIES:
  :CUSTOM_ID: jaccard-index-versus-accuracy
  :END:
Depending on the use-case some metrics are sub-optimal for determining
segmentation quality. We demonstrate this by comparing segmentation
results on differently cropped images.

See also:

- [[https://arxiv.org/abs/2206.01653][Maier-Hein, Reinke et al. (Arxiv
  2023). Metrics reloaded: Pitfalls and recommendations for image
  analysis validation]]

<<abb6988a-077c-474a-9255-8d23b5aeb48c>>
#+begin_src python
from skimage.data import human_mitosis
from the_segmentation_game import metrics
import napari_segment_blobs_and_things_with_membranes as nsbatwm
import stackview
#+end_src

<<425d990b-d660-4676-b076-261255eefd71>>
We use the =human_mitosis= example dataset from scikit-image.

<<2ff66847-93cf-4551-befe-2f0da40f21e2>>
#+begin_src python
image = human_mitosis()[95:165, 384:454]

stackview.insight(image)
#+end_src

#+begin_example
StackViewNDArray([[10, 11,  9, ..., 11, 11, 10],
                  [10, 10, 11, ..., 12, 12, 11],
                  [ 9,  9, 10, ..., 12, 11, 11],
                  ...,
                  [10,  9,  9, ..., 11, 12, 11],
                  [10, 10, 10, ..., 13, 12, 12],
                  [10, 10, 10, ..., 13, 13, 13]], dtype=uint8)
#+end_example

<<5a499359-ffed-449a-9311-fa51f2a474f8>>
Let's assume this is a reference annotation performed by an expert.

<<8682b2a0-c471-415c-a08b-a33ae0c272a4>>
#+begin_src python
reference_labels = nsbatwm.voronoi_otsu_labeling(image)
reference_labels
#+end_src

#+begin_example
StackViewNDArray([[0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0],
                  ...,
                  [0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0]])
#+end_example

<<4d037de8-23a1-4e5d-90c3-b2fec0fcff3f>>
Furthermore, this create a segmentation result we would like to
determine the quality of.

<<08a19089-92ea-4920-aa44-b019faf6ae5b>>
#+begin_src python
test_labels = nsbatwm.gauss_otsu_labeling(image, outline_sigma=3)

test_labels
#+end_src

#+begin_example
StackViewNDArray([[0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0],
                  ...,
                  [0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0]])
#+end_example

<<53229a19-b2bb-4910-9f9d-682387975ce3>>
** Quality measurement
   :PROPERTIES:
   :CUSTOM_ID: quality-measurement
   :END:
There are plenty of quality metrics for measuring how well the two label
images fit to each other. In the following we use
[[https://github.com/haesleinhuepf/the-segmentation-game#metrics][accuracy
and jaccard index as implemented in The Segmentation Game]], a
napari-plugin for measuring quality metrics of segmentation results.

<<9a3ff87a-4653-417f-9f60-1d0a551f58cc>>
#+begin_src python
metrics.roc_accuracy_binary(reference_labels, test_labels)
#+end_src

#+begin_example
0.9744898
#+end_example

<<e990bce5-d0e9-483a-a90c-78b7d43cc549>>
#+begin_src python
metrics.jaccard_index_sparse(reference_labels, test_labels)
#+end_src

#+begin_example
0.7274754206261056
#+end_example

<<98f221fb-113e-4efa-9ffc-4fd349a4bcf3>>
We will now apply the same metrics to the label image again, but crop
the label image by removing some of the zero-value pixels in the top and
left of the label image.

<<a824e910-e224-4ae6-ba45-bf4ded55b895>>
#+begin_src python
metrics.roc_accuracy_binary(reference_labels[20:,20:], test_labels[20:,20:])
#+end_src

#+begin_example
0.95
#+end_example

<<02d9bee7-834d-4675-8344-31cafbec1dde>>
#+begin_src python
metrics.jaccard_index_sparse(reference_labels[20:,20:], test_labels[20:,20:])
#+end_src

#+begin_example
0.7274754206261056
#+end_example

<<a252ee6f-809f-47a0-beb9-221ad23605ce>>
As you can see, the accuracy metric changes, while the Jaccard Index
does not. Obviously the accuracy metric depends on the amount of
zero-value pixels in the label image. We just visualize the cropped
images:

<<dde2cf25-3480-43aa-92a5-d1de6cf5169b>>
#+begin_src python
reference_labels[20:,20:]
#+end_src

#+begin_example
StackViewNDArray([[0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0],
                  ...,
                  [0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0]])
#+end_example

<<3505144b-d036-4d12-a903-15c8358f8ace>>
#+begin_src python
test_labels[20:,20:]
#+end_src

#+begin_example
StackViewNDArray([[0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0],
                  ...,
                  [0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0],
                  [0, 0, 0, ..., 0, 0, 0]])
#+end_example

<<217cf4bd-25f2-4135-9539-59f895d71f38>>
** Explanation
   :PROPERTIES:
   :CUSTOM_ID: explanation
   :END:
When comparing the equations of accuracy \(A\) and Jaccard index \(J\),
it is obvious that both do the same kind-of, but only accuracy includes
the number of zero-value pixels in both label images. These pixels are
the true-negatives \(TN\).

\[
  A =\frac{TP + TN}{FN + FP + TP + TN}
\]

\[
  J =\frac{TP}{FN + FP + TP}
\]

<<58a5636b-467a-4865-9609-7735a1b2d98a>>
#+begin_src python
#+end_src
